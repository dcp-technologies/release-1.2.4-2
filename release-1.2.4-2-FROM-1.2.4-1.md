# PROCEDURE POUR APPLIQUER LE PATCH 1.2.4-2 A PARTIR DU PATCH 1.2.4-1

# Nouvelles Images du patch 1.2.4

## ðŸ”¹ API
- `docker.io/dcptechnologies/api:1.2.4-2`
- `docker.io/dcptechnologies/logwatcher:1.2.4-2`
- `docker.io/dcptechnologies/podwatcher:1.2.4-2`
- `docker.io/dcptechnologies/health:1.2.4-2`

## ðŸ”¹ PROXY
- `docker.io/dcptechnologies/proxy:1.0.0-v3`

## ðŸ”¹ SPARK
- `docker.io/dcptechnologies/spark:sp-350-124-v1`
- `docker.io/dcptechnologies/notebook:nb-350-124-v1`

## ðŸ”¹ SQL
- `docker.io/dcptechnologies/sql:hbase`
- `docker.io/dcptechnologies/sql:470`
- `docker.io/dcptechnologies/sql:hms-3.1.2-v3`
- `docker.io/dcptechnologies/sql:policy-1.2.4-2`

## ðŸ”¹ DASK
- `docker.io/dcptechnologies/dask:2024.9.1-py3.11`
- `docker.io/dcptechnologies/dask:24.10-cuda12.5-py3.12`
- `docker.io/dcptechnologies/dask:nb-sp350-dask2024.8.0`
- `docker.io/dcptechnologies/dask:nb-gpu-sp350-dask2024.8.0`

## ðŸ”¹ Dbt
- `dcptechnologies/dbt:proxy-1.9.2-1`
- `docker.io/dcptechnologies/dbt:storageinitializer-1.2.4`

## ðŸ”¹ File manager
- `docker.io/dcptechnologies/filemanager:1.2.4`

## ðŸ”¹ DÃ©mo Spark GPU
- `docker.io/dcptechnologies/demo-spark-gpu:1.2.4`

## ðŸ”¹ Airflow DAG Editor
- `docker.io/dcptechnologies/airflow:editor`

---

# VÃ©rification de la Sauvegarde de la Base de DonnÃ©es  
Avant toute mise Ã  jour, **s'assurer que la base de donnÃ©es a bien Ã©tÃ© sauvegardÃ©e**.

---


# Installation du Package
1. **TÃ©lÃ©charger** le package d'installation.
2. **Copier** les rÃ©pertoires `env` et `certs` de l'ancien package d'installation.
3. **Modifier** le fichier `env.sh` :  
    ```sh
    API_VERSION=1.2.4-2
    ```
4. Modifier le fichier env-api.sh
    ```sh
    MASTER_API_VERSION=$API_VERSION
    ```
5. **Modifier** le fichier `env-podwatcher.sh` :
    ```sh
    PODWATCHER_CLEANCONFIGMAP=true
    PODWATCHER_CLEANSERVICE=true
    PODWATCHER_CLEANVOLUME=true
    ```
6. **Modifier** le fichier `env-scheduler.sh` :
    ```sh
    SCHEDULER_REQUESTCPU=4
    SCHEDULER_LIMITCPU=4
    SCHEDULER_REQUESTMEMORY=10Gi
    SCHEDULER_LIMITMEMORY=10Gi
    GOGC=200
    GOMEMORYLIMIT=8GiB
    ```
6. **Modifier** le fichier `env-proxy.sh`:
    Activer le SSL et renseigner la nouvelle version du proxy: chercher et modifier les  paramÃ¨tre:
    ```sh
    PROXY_VERSION=1.0.0-v3
    PROXY_SSL_ENABLED=$SSL_ENABLED
    ```
    Ajouter nouveaux paramÃ¨tres
    ```sh
    DCPRANDOMUUID="xWFlmUb8Jxbz"
    DCPRANDOMUUIDLABEL="dcprandomuuid"
    MASTER_CLUSTER_ROLE=$CLUSTERROLE
    MASTER_NAMESPACES=$ROLE_NAMESPACES
    ```
7. Copier les certificats de l'ancien package d'installation dans :
    ```
    repos/master-api/files
    ```

---

# ArrÃªter les Services DCP et le PROXY DCP
Avant dâ€™arrÃªter les services DCP, vÃ©rifier quâ€™aucun traitement Spark nâ€™est en cours.
Ensuite, exÃ©cuter la commande suivante :

```sh
helm -n dcp uninstall dcpapi dcphealth dcplog dcppodwatcher-primary dcppodwatcher-backup dcppodwatcher-secondary masterproxy
```

---

# Upgrade de la base de donnÃ©es
```sh
./upgradedatabase-1.2.4-2.sh
```
VÃ©rifier les log du job "upgrade-postgresql-job-124-2"

---

# Installation et Mise Ã  Jour des Composants

## ðŸ”¹ Installer lâ€™API

```sh
./09-api.sh
```

## ðŸ”¹ Mettre Ã  jour les modÃ¨les

```sh
./10-models.sh
```

## ðŸ”¹ Mettre Ã  jour les repositories
```sh
./11-repos.sh
```

## ðŸ”¹ Installer le Log Watcher
```sh
./12-logwatcher.sh
```

## ðŸ”¹ Installer le Pod Watcher

```sh
./13-podwatcher.sh primary
./13-podwatcher.sh secondary
./13-podwatcher.sh backup
```

# Installer le health-checker
```sh
./14-health.sh
```

# Installer le proxy
```sh
./06-proxy.sh
```
Consulter les logs du du pod "proxy", afin de vÃ©rifier que le service est dÃ©marrÃ© en SSL:
```
DÃ©marrage du serveur HTTPS sur le port 8080...
```

---

# Configuration Globale
1. Se rendre dans le menu Admin.
2. Aller dans Kubernetes. et selÃ©ctionner ***local*** dans la liste

## ðŸ”¹ Scheduler
Aller dans l'onglet "Scheduler
Activer l'option "Queue # from tenant"

## ðŸ”¹ Activer SSL pour Dask
Aller dans l'onglet "Dask"
- Activer SSL pour Dask en cochant l'option "Enable SSL"


## ðŸ”¹ Activer SSL pour Dbt
Aller dans l'onglet "Dbt"
- Activer SSL pour Dbt en cochant l'option "Enable SSL"

## ðŸ”¹ Spark
Aller dans l'onglet ***Spark***
Aller dans l'onglet ***Spark History***
 - Activer SSL pour Spark History en cochant l'option "Enable TLS"
Aller dans l'onglet ***Spark Monitoring***
 - Activer SSL pour Spark Monitoring en cochant l'option "Enable TLS"
Aller dans l'onglet ***Spark Notebook***
 - Activer SSL pour Spark Notebook en cochant l'option "Enable TLS" 

## ðŸ”¹ Airflow
Aller dans l'onglet ***Airflow***
 - Activer SSL pour Airflow en cochant l'option "Enable TLS"
 - Dans l'onglet ***Dag Editor*** saisir la valeur 4 dans les champs:
    ```
    Minimum Core
    Minimum Memory
    Maximum Core
    Maximum Memory
    ```
 - Dans l'onglet ***Metrics Storage*** saisir la valeur 4 dans les champs:
    ```
    Request CPU = 2
    Request Memory = 2
    Limit CPU = 2
    limit Memory = 2
    ```
 - Dans l'onglet ***Sync Config***, saisir les valeurs suivantes dasn chaque champ
    ```
    Request CPU = 1
    Request Memory = 1
    Limit CPU = 2
    limit Memory = 2
    ```
 - Dans l'onglet ***Dashboard Config***: 
    1. Activer SSL pour le monitoring Airflow en cochant l'option "Enable SSL"
    2. saisir les valeurs suivantes dasn chaque champ
    ```
    Request CPU = 2
    Request Memory = 2
    Limit CPU = 2
    limit Memory = 2
    ```

## ðŸ”¹ GPU
Aller dans l'onglet ***GPU*** et utiliser le bouton "Add provide/label" pour ajouter les labels mig pour gpu.

# PARAMS
## ðŸ”¹ GPU
Aller dans l'onglet ***Global***
VÃ©rifier que le champ "bucketprovider" contient la valeur Scality
```
bucketprovider='Scality'
```

VÃ©rifier que le champ "Uid" contient la valeur xWFlmUb8Jxbz
```
Uid='xWFlmUb8Jxbz'
```


VÃ©rifier que les options suivantes sont activÃ©es:
```
onlyadmincanmodifysc
showsource
checkserviceauthbydata
```

## ðŸ”¹ Repos
Aller dans l'onglet ***Global***
```
mlflowrepo: mlflow
mlprojectflaskagent: mlflow
daskrepo: dask
filemanagerrepo: dcpfm
```


# Hive Metastore
1. Se rendre dans le menu ***Sql***.
2. Se rendre dans le menu ***Metastore***
Le service ***Metastore*** ne supporte plus de prendre en charge plusieurs buckets. 
SÃ©lectionner chaque metastore et sÃ©lectionner la bucket Ã  lui associer.

# PATCH
```
Avant d'appliquer le patch des service "Sql policy", s'assurer que tous ces services sont dÃ©marrÃ©es, sinon le patch ne s'appliquera pas correctement
```
Patch Sql Policy
```

# Sql Policy
RedÃ©marrer tous les services ***Sql Policy*** pour utiliser la derniÃ¨re version qui apporte des amÃ©liorations
